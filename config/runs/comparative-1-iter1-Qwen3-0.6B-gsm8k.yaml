run_id: comparative-1-iter1-Qwen3-0.6B-gsm8k
method: lagnas_nacus
model:
  base_model: Qwen3-0.6B
  precision: bf16
  lora:
    r0: 16
    alpha: 32
    dropout: 0.05
    target_modules: ["c_attn", "c_proj", "w1", "w2"]
  nacus:
    gate_threshold: 0.05   # magnitude criterion for saturation
    disable_grad_skip: false
dataset:
  name: gsm8k
  config: main
  text_column: question
  label_column: answer
  max_length: 1024
  train_split: train
  eval_split: test
  num_workers: 8
training:
  epochs: 3
  micro_batch_size: 8
  gradient_accumulation_steps: 8
  effective_batch_size: 64
  learning_rate: 3e-4
  optimizer: adamw
  betas: [0.9, 0.98]
  weight_decay: 0.01
  scheduler: cosine
  warmup_steps: 200
  max_grad_norm: 1.0
  seed: 42
logging:
  eval_every_n_steps: 500
  save_every_n_steps: 2000
  output_dir: outputs/lagnas_nacus
optuna:
  n_trials: 30
  direction: maximize
  metric: dev_exact_match
  pruning:
    patience: 300
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-4
      high: 5e-4
    batch_size:
      type: categorical
      choices: [32, 64, 96]
    weight_decay:
      type: uniform
      low: 0.0
      high: 0.05
